{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate biomass with GEE JS\n",
    "\n",
    "  Documentation on how to create a microservice with GE engine. In this specific case it \n",
    "  calculates biomass and biomass density paralelly for all admin 2 regions in the GADM table\n",
    "  by using the map() function. It can be used as a model to calculate other attributes. \n",
    "  We start off by getting the GADM admin 2 areas from https://gadm.org/download_world.html (click on download as six separate layers, then take only level_2). To preprocess the data, some simple python code is used to get rid of unnecessary columns.\n",
    "  ```python \n",
    "df = gpd.read_file('/Users/nrigheriu/vizzuality/data/gadm36_level2_shp/gadm36_2.shp', encoding='utf-8')\n",
    "iso_col = ['blah'] * len(df)\n",
    "df['iso'] = iso_col\n",
    "df['admin_1'] = iso_col\n",
    "df['admin_2'] = iso_col\n",
    "def process_gid_2(gid_2):\n",
    "    \"\"\"Return dict of iso (string), and admin_1 and admin_2 (ints) from gid_2 entry.\"\"\"\n",
    "    try:\n",
    "        iso, admin_1, tmp_admin_2 = gid_2.split('.')\n",
    "        admin_2 = tmp_admin_2.split('_')[0]\n",
    "        return {'iso':iso, 'admin_1':int(admin_1), 'admin_2':int(admin_2)}\n",
    "    except:\n",
    "        return {'iso':\"\", 'admin_1':\"\", 'admin_2':\"\"}\n",
    "gid_split = [process_gid_2(df['GID_2'][i]) for i in range(len(df['GID_2']))]\n",
    "df['iso'] = [gid_split[i]['iso'] for i in range(len(gid_split))] \n",
    "df['admin_1'] = [gid_split[i]['admin_1'] for i in range(len(gid_split))] \n",
    "df['admin_2'] = [gid_split[i]['admin_2'] for i in range(len(gid_split))] \n",
    "out_df = gpd.GeoDataFrame(df[['GID_2','iso', 'admin_1', 'admin_2']],geometry=df.geometry, crs=df.crs)\n",
    "!mkdir world_parsed_gid\n",
    "out_df.to_file(driver = 'ESRI Shapefile', filename='world_parsed_gid/world_parsed_gid.shp')\n",
    "```\n",
    "Afterwards the shapefile is inserted in http://mapshaper.org/ and the features are simplified to about 1% to make sure it will be accepted in earth engine when uploading it as a table (here it's named gadm36).\n",
    "  Beware the script takes several hours (>4 hrs) to complete. For smaller scale experiments, try using a data set like regions of Spain first. \n",
    "  Firstly start off by importing the gadm table containing admin level geometries and the \n",
    "  other 2 tables whrc_carbon and forest_change to help in calculating biomass. \n",
    "```javascript\n",
    "var whrc_carbon = ee.ImageCollection(\"projects/wri-datalab/WHRC_CARBON\"),\n",
    "    forest_change = ee.Image(\"projects/wri-datalab/HansenComposite_17\"),\n",
    "    gadm36 = ee.FeatureCollection(\"projects/wri-datalab/gadm36\");\n",
    "\n",
    "```\n",
    "  The function addBiomass() has a threshold parameter which corresponds to the dataset \n",
    "  being passed (e.g. thresholdVal 10 for dataset th10) and adds a threshold property as \n",
    "  well as biomass and biomassDensity density corresponding to this threshold value \n",
    "  for all the entries in gadm36 (which consists of admin2 areas). \n",
    "  After adding the threshold property,  a mask with tree cover is created with help \n",
    "  of the forest_change data. \n",
    "  The addBiomassSum function gets the biomass_masked property and uses the Reducer function to create \n",
    "  a new attribute called biomass. It does so with the feature.set() function. \n",
    "  Afterwards, the biomassSum attribute is stored in a variable and used to calculate and add a new attribute\n",
    "  called biomassDensity which is the biomassSum divided by the area. Finally the geometry of the features is \n",
    "  deleted by setting it to null because it isn't needed anymore.\n",
    "  \n",
    "  NOTE: feature properties/attributes cannot be printed inside the map() function because it is executed \n",
    "  in paralell on different machines. The code has to be written and trusted that it works or debugged in \n",
    "  a different way.   \n",
    "```javascript\n",
    "var addBiomass = function(thresholdVal) {\n",
    "   var addThreshold = function(feature) {\n",
    "    return feature.set({threshold: thresholdVal});\n",
    "  };\n",
    "  var addArea = function(feature) {\n",
    "    return feature.set({areaHa: feature.geometry().area().divide(100 * 100)});\n",
    "  };\n",
    "  var dataset = gadm36.map(addThreshold);\n",
    "  dataset = dataset.map(addArea);\n",
    "  var tree_mask = forest_change.select('tree_' + thresholdVal).gt(0);\n",
    "  var biomass_masked = whrc_carbon.max().multiply(ee.Image.pixelArea().divide(10000)).mask(tree_mask);\n",
    "  var addBiomassSum = function(feature) {\n",
    "    feature = feature.set({biomass: biomass_masked.reduceRegion({\n",
    "      reducer: ee.Reducer.sum().unweighted(),\n",
    "      geometry: feature.geometry(),\n",
    "      bestEffort: true,\n",
    "      scale:30 }).get('b1')});              //The actual calculated biomass is in the attribute b1\n",
    "    var areaHa = ee.Number(feature.get('areaHa'));\n",
    "    var biomassSum = ee.Number(feature.get('biomass'));\n",
    "    feature = feature.set({biomassDensity: biomassSum.divide(areaHa)})\n",
    "                      .setGeometry(null); \n",
    "    return feature; \n",
    "  };\n",
    "  dataset = dataset.map(addBiomassSum);\n",
    "  return dataset;\n",
    "}; \n",
    "```\n",
    "   To have a final table with each original values duplicated for each of the threshold values,\n",
    "   multiple datasets are created and merged. Finally, the table will consist of 7 times \n",
    "   more rows (as there are 7 different threshold values), where the extra added rows contain\n",
    "   the same data as the original ones, except the values indicating threshold, \n",
    "   biomass and biomassDensity.    \n",
    "```javascript\n",
    "var th10 = addBiomass(10);\n",
    "var th15 = addBiomass(15);\n",
    "var th20 = addBiomass(20);\n",
    "var th25 = addBiomass(25);\n",
    "var th30 = addBiomass(30);\n",
    "var th50 = addBiomass(50);\n",
    "var th75 = addBiomass(75);\n",
    "var final_table = th10.merge(th15);\n",
    "final_table = final_table.merge(th20);\n",
    "final_table = final_table.merge(th25);\n",
    "final_table = final_table.merge(th30);\n",
    "final_table = final_table.merge(th50);\n",
    "final_table = final_table.merge(th75);\n",
    "```\n",
    "The table needs to be exported, and not printed because it is too large to be printed. \n",
    "```javascript\n",
    "//print(gadm36);  //don't print or else it'll cause scaling errors\n",
    "Export.table.toCloudStorage({\n",
    "  collection: final_table,\n",
    "  description: 'gadm36BiomassTHs',\n",
    "  fileFormat: 'CSV'\n",
    "});\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
